# -*- coding: utf-8 -*-
"""Copy of Proyek Akhir Data Science.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15nwpv7pA8HDaoYm7hyQ0TkOAjwK0kVVz

# **Proyek Akhir: Menyelesaikan Permasalahan di Jaya Jaya Institut**


*   Nama : Suyanti Witono
*   Email: suyanti.witono@bpkpenaburjakarta.or.id
*   ID Dicoding: suyanti_witono_tFDe

## **1. Project Overview**

> *Dropout* adalah kondisi di mana seseorang diharuskan berhenti dari institusi pendidikan atau tempat kerja sebelum menyelesaikan masa studinya atau kontrak kerjanya. (Dealls, 2025)

Menurut Kemendikbudristek, jumlah mahasiswa dan pelajar di Indonesia yang mengalami *dropout* pada tahun 2021 mencapai 480.449 orang. Angka tersebut cukup tinggi dan memprihatinkan. Apalagi pendidikan adalah hal penting dan merupakan kebutuhan dasar manusia. Pendidikan tinggi yang berkualitas juga merupakan hak bagi seluruh warga negara.

Beberapa faktor yang mempengaruhi tingkat putus sekolah/pendidikan ini antara lain faktor ekonomi (penghasilan, pendidikan kepala rumah tangga) serta akses ke fasilitas pendidikan (daerah tempat tinggal) (Hakim, 2020). Untuk pendidikan tinggi, kurangnya motivasi mahasiswa dan hasil akademik/performa mahasiswa juga mempengaruhi tingkat *dropout*. '

Dengan data yang lengkap, angka *dropout* dapat diprediksi menggunakan model *Machine Learning* (Hidayat et al, 2013). Hal ini akan memberikan gambaran kepada pihak penyelenggara pendidikan untuk dapat melakukan langkah-langkah pencegahan dropout yang tepat.

### **Referensi (APA Style)**
1. Dealls (2025). Drop Out: Arti, Faktor Penyebab & Dampaknya! | Dealls. [online] Dealls. Available at: https://dealls.com/pengembangan-karir/drop-out-artinya.
2. Hakim, A. (2020). FAKTOR PENYEBAB ANAK PUTUS SEKOLAH. Jurnal Pendidikan, 21(2), pp.122–132. doi:https://doi.org/10.33830/jp.v21i2.907.2020.
3. Hidayat, M. Mahaputra & Purwitasari, Diana & Ginardi, R.V.Hari. (2013). ANALISIS PREDIKSI DROP OUT BERDASARKAN PERILAKU SOSIAL MAHASISWA DALAM EDUCATIONAL DATA MINING MENGGUNAKAN JARINGAN SYARAF TIRUAN. IPTEK ITATS.

## **2. Business Understanding**

Jaya Jaya Institut merupakan salah satu institusi pendidikan perguruan yang telah berdiri sejak tahun 2000 dan telah mencetak banyak lulusan dengan reputasi yang sangat baik. Akan tetapi, banyak siswa yang tidak menyelesaikan pendidikannya (*drop out*). Jaya Jaya Institut mau memperoleh gambaran mengenai siswa yang berpotensi untuk *drop out* sehingga dapat dilakukan pendekatan khusus agar mereka menyelesaikan pendidikannya.

### *Permasalahan Bisnis*

Mari kita mengevaluasi beberapa faktor yang mungkin menyebabkan *dropout* tersebut.
1. Bagaimana demografi siswa (status pernikahan, usia, gender), serta kehadiran di kelas pagi/sore mempengaruhi *dropout*?
2. Bagaimana hubungan antara tingkat pendidikan orangtua dan pekerjaan orangtua terhadap *dropout*?
3. Apa hubungan antara tingkat pendidikan siswa dan nilai sebelumnya terhadap hasil siswa (*dropout* atau lulus)?
4. Bagaimana perbandingan *trend curricular units* semester 1 dan semester 2 yang dikreditkan, didaftarkan, dievaluasi dan disetujui oleh siswa?
5. Bagaimana tingkat *dropout* berdasarkan *course* yang diambil siswa?
6. Apa pengaruh beasiswa terhadap siswa *dropout*?

### *Cakupan Proyek:*
Melakukan analisa data untuk menentukan faktor-faktor yang menyebabkan tingginya *dropout* sehingga dapat dilakukan tindakan/program pendekatan untuk mencegah siswa *dropout*.

## **3. Data Understanding**

### Sumber data

File CSV: raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv
"""

import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv', delimiter=";")

df.head(5)

"""### Keterangan dataset
Terdiri dari 37 kolom:
1. Marital status (kategorikal): status pernikahan siswa (1-belum menikah, 2-menikah, 3-cerai mati, 4-cerai hidup, 5-hidup bersama, 6-berpisah).
2. Application mode (kategorikal): Metode aplikasi yang digunakan siswa (1-fase 1-umum, 2-Ordinance No. 612/93, 5-fase 1-kontingen khusus (Azores Island), 7-lulusan pendidikan tinggi lainnya, 10-Ordinance No. 854-B/99, 15-siswa internasional (S1), 16-fase 1-kontingen khusus (Madeira Island), 17-fase 2-kontingen khusus, 18-fase 3-kontingen khusus, 26-Ordinance No. 533-A/99, item b2 (Different Plan), 27-Ordinance No. 533-A/99, item b3 (Other Institution), 39-di atas 23 tahun, 42-transfer, 43-mengubah jurusan, 44-lulusan diploma spesialis teknik, 51-mengubah institusi, 53-lulusan diploma jarak pendek, 57-mengubah institusi/jurusan (internasional)).
3. Application order (numerikal): urutan siswa mendaftar (0-pilihan pertama sampai 9-pilihan terakhir).
4. Course (kategorikal): Jurusan yang diambil siswa (33-Biofuel Production Technologies, 171-Animation and Multimedia Design, 8014-Social Service (evening attendance), 9003-Agronomy, 9070-Communication Design, 9085-Veterinary Nursing, 9119-Informatics Engineering, 9130-Equinculture, 9147-Management, 9238-Social Service, 9254-Tourism, 9500-Nursing, 9556-Oral Hygiene, 9670-Advertising and Marketing Management, 9773-Journalism and Communication, 9853-Basic Education, 9991-Management (evening attendance)).
5. Daytime/evening attendance (kategorikal): Apakah siswa menghadiri kelas pagi/sore (1-pagi, 0-sore).
6. Previous qualification (kategorikal): kualifikasi yang diselesaikan siswa sebelumnya (1-SMA atau setingkat, 2-S1, 3-diploma, 4-S2, 5-S3, 6-setara pendidikan tinggi, 9-tidak menyelesaikan 12 tahun sekolah, 10-tidak menyelesaikan 11 tahun sekolah, 12-Lain-lain-11 tahun sekolah, 14-10 tahun sekolah, 15-tidak menyelesaikan 10 tahun sekolah, 19-Basic education 3rd cycle (9th/10th/11th year) atau setara, 38-Basic education 2nd cycle (6th/7th/8th year) atau setara, 39-spesialis teknologi (SMK), 40-Higher education - degree (1st cycle), 42-Professional higher technical course, 43-Higher education - master (2nd cycle)).
7. Previous qualification (grade): Nilai siswa yang didapat pada pendidikan sebelumnya (0-200).
8. Nacionality (kategorikal): kebangsaan dari siswa (1-Portuguese, 2-German, 6-Spanish, 11-Italian, 13-Dutch, 14-English, 17-Lithuanian, 21-Angolan, 22-Cape Verdean, 24-Guinean, 25-Mozambican, 26-Santomean, 32-Turkish, 41-Brazilian, 62-Romanian, 100-Moldova (Republic of), 101-Mexican, 103-Ukrainian, 105-Russian, 108-Cuban, 109-Colombian).
9. Mother's qualification (kategorikal): Tingkat pendidikan ibu (1-Secondary Education - 12th Year of Schooling or Eq., 2-Higher Education-Bachelor's Degree, 3-Higher Education-Degree, 4-Higher Education-Master's, 5-Higher Education-Doctorate, 6-Frequency of Higher Education, 9-12th Year of Schooling-Not Completed, 10-11th Year of Schooling-Not Completed, 11-7th Year (Old), 12-Other-11th Year of Schooling, 14-10th Year of Schooling, 18-General commerce course, 19-Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv., 22-Technical-professional course, 26-7th year of schooling, 27-2nd cycle of the general high school course, 29-9th Year of Schooling-Not Completed, 30-8th year of schooling, 34-Unknown, 35-Can't read or write, 36-Can read without having a 4th year of schooling, 37-Basic education 1st cycle (4th/5th year) or equiv., 38-Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv., 39-Technological specialization course, 40-Higher education-degree (1st cycle), 41-Specialized higher studies course, 42-Professional higher technical course, 43-Higher Education-Master (2nd cycle), 44-Higher Education-Doctorate (3rd cycle)).
10. Father's qualification (kategorikal): Tingkat pendidikan ayah (1-Secondary Education - 12th Year of Schooling or Eq., 2-Higher Education-Bachelor's Degree, 3-Higher Education-Degree, 4-Higher Education-Master's, 5-Higher Education-Doctorate, 6-Frequency of Higher Education, 9-12th Year of Schooling-Not Completed, 10-11th Year of Schooling-Not Completed, 11-7th Year (Old), 12-Other-11th Year of Schooling, 14-10th Year of Schooling, 18-General commerce course, 19-Basic Education 3rd Cycle (9th/10th/11th Year) or Equiv., 22-Technical-professional course, 26-7th year of schooling, 27-2nd cycle of the general high school course, 29-9th Year of Schooling-Not Completed, 30-8th year of schooling, 34-Unknown, 35-Can't read or write, 36-Can read without having a 4th year of schooling, 37-Basic education 1st cycle (4th/5th year) or equiv., 38-Basic Education 2nd Cycle (6th/7th/8th Year) or Equiv., 39-Technological specialization course, 40-Higher education-degree (1st cycle), 41-Specialized higher studies course, 42-Professional higher technical course, 43-Higher Education-Master (2nd cycle), 44-Higher Education-Doctorate (3rd cycle)).
11. Mother's occupation (kategorikal): Pekerjaan ibu (0-Siswa, 1-Perwakilan dari badan legislatif dan/atau eksekutif, direktur, dan manajer eksekutif, 2-Spesialis dalam kegiatan Intelektual dan Saintifik, 3-Teknisi dan Profesi Level Menengah, 4-Staf Admin, 5-Personal Services, Security and Safety Workers and Penjual, 6-Petani dan Pekerja Ahli di bidang agrikultur, perikanan and perhutanan, 7-Pekerja Ahli di industri, konstruksi, pengrajin, 8-Pekerja dan operator instalasi dan mesin, 9-Pekerja (non ahli), 10-Tentara, 90-Situasi lain, 99-(kosong/tidak ada keterangan), 122-tenaga medis/kesehatan, 123-guru, 125-Spesialis dalam Information and communication technologies (ICT), 131-Teknisi dan Staf Ahli Level menengah dalam science and engineering, 132-Teknisi atau Staf Ahli level menengah dalam bidang kesehatan, 134-Teknisi atau Staf Ahli level menengah dalam hukum, sosial, olahraga, kebudayaan dan sejenisnya, 141-Pekerja kantor, sekretaris, dan operator data, 143-Operator dalam bidang accounting, statistical, financial services, 144-Staf admin pendukung, 151-Pekerja jasa personal, 152-pedagang, 153-Personal care workers, 171-Staf Ahli konstruksi dan sejenisnya, kecuali electricians, 173-pelukis, penghasil instrumen presisi, pembuat perhiasan, artisans dan sejenisnya, 175-Pekerja dalam pembuatan makanan, pembuat kayu, pakaian, dan industri lainnya, 191-petugas kebersihan, 192-Tenaga kerja kasar dalam pertanian, perikanan, peternakan, dan kehutanan, 193-Tenaga kerja kasar dalam pertambangan, produksi, dan transportasi, 194-Asisten juru masak).
12. Father's occupation (kategorikal): Pekerjaan ayah (0-Siswa, 1-Perwakilan dari badan legislatif dan/atau eksekutif, direktur, dan manajer eksekutif, 2-Spesialis dalam kegiatan Intelektual dan Saintifik, 3-Teknisi dan Profesi Level Menengah, 4-Staf Admin, 5-Personal Services, Security and Safety Workers and Penjual, 6-Petani dan Pekerja Ahli di bidang agrikultur, perikanan and perhutanan, 7-Pekerja Ahli di industri, konstruksi, pengrajin, 8-Pekerja dan operator instalasi dan mesin, 9-Pekerja (non ahli), 10-Tentara, 90-Situasi lain, 99-(kosong/tidak ada keterangan), 122-tenaga medis/kesehatan, 123-guru, 125-Spesialis dalam Information and communication technologies (ICT), 131-Teknisi dan Staf Ahli Level menengah dalam science and engineering, 132-Teknisi atau Staf Ahli level menengah dalam bidang kesehatan, 134-Teknisi atau Staf Ahli level menengah dalam hukum, sosial, olahraga, kebudayaan dan sejenisnya, 141-Pekerja kantor, sekretaris, dan operator data, 143-Operator dalam bidang accounting, statistical, financial services, 144-Staf admin pendukung, 151-Pekerja jasa personal, 152-pedagang, 153-Personal care workers, 171-Staf Ahli konstruksi dan sejenisnya, kecuali electricians, 173-pelukis, penghasil instrumen presisi, pembuat perhiasan, artisans dan sejenisnya, 175-Pekerja dalam pembuatan makanan, pembuat kayu, pakaian, dan industri lainnya, 191-petugas kebersihan, 192-Tenaga kerja kasar dalam pertanian, perikanan, peternakan, dan kehutanan, 193-Tenaga kerja kasar dalam pertambangan, produksi, dan transportasi, 194-Asisten juru masak).
13. Admission grade (numerikal): nilai ujian masuk (antara 0-200).
14. Displaced (kategorikal): Apakah siswa cacat? (1-ya, 0-tidak).
15. Educational special needs (kategorikal): Apakah siswa berkebutuhan khusus? (1-ya, 0-tidak).
16. Debtor (kategorikal): Apakah siswa memiliki hutang? (1-ya, 0-tidak).
17. Tuition fees up to date (kategorikal): Apakah uang sekolah siswa sudah status terbaru? (1-ya, 0-tidak).
18. Gender (kategorikal): jenis kelamin siswa. (1-laki-laki, 0-perempuan).
19. Scholarship holder (kategorikal): apakah siswa mendapatkan beasiswa? (1-ya, 0-tidak).
20. Age at enrollment (numerikal): usia siswa saat diterima di institut.
21. International (kategorikal): (1-ya, 0-tidak).
22. Curricular units 1st sem (credited) (numerikal): jumlah curricular units yang dikreditkan oleh siswa pada semester pertama.
23. Curricular units 1st sem (enrolled) (numerikal): jumlah curricular units yang didaftar oleh siswa pada semester pertama.
24. Curricular units 1st sem (evaluations) (numerikal): jumlah curricular units yang dievaluasi oleh siswa pada semester pertama.
25. Curricular units 1st sem (approved) (numerikal): jumlah curricular units yang disetujui oleh siswa pada semester pertama.
26. Curricular units 1st sem (grade) (numerikal): rata-rata nilai siswa semester pertama (0-20).
27. Curricular units 1st sem (without evaluations) (numerikal): jumlah curricular units tanpa evaluasi di semester 1.
28. Curricular units 2nd sem (credited) (numerikal): jumlah curricular units yang dikreditkan oleh siswa pada semester kedua.
29. Curricular units 2nd sem (enrolled) (numerikal): jumlah curricular units yang didaftar oleh siswa pada semester kedua.
30. Curricular units 2nd sem (evaluations) (numerikal): jumlah curricular units yang dievaluasi oleh siswa pada semester kedua.
31. Curricular units 2nd sem (approved) (numerikal): jumlah curricular units yang disetujui oleh siswa pada semester kedua.
32. Curricular units 2nd sem (grade) (numerikal): rata-rata nilai siswa semester kedua (0-20).
33. Curricular units 2nd sem (without evaluations) (numerikal): jumlah curricular units tanpa evaluasi di semester 2.
34. Unemployment rate (numerikal): persentase tidak bekerja.
35. Inflation rate (numerikal): persentase angka inflasi.
36. GDP (numerikal): jumlah produk berupa barang dan jasa, yang dihasilkan oleh unit-unit produksi di dalam batas wilayah suatu negara selama satu tahun.
37. Status (kategorikal): status siswa pada akhir tahun pembelajaran (Dropout, Graduate, Enrolled).

### Menyiapkan library yang dibutuhkan
"""

pip install pandas sqlalchemy

from sqlalchemy import create_engine

# Update the URL with the correct password
URL = "postgresql://postgres.dtidwxrpgndkiojmbleq:TerusBelajar@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres"

engine = create_engine(URL)
df.to_sql('students_performance', engine, if_exists='replace', index=False)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""### Mengecek Tipe Data per Kolom"""

df.info()

"""Tipe data pada kolom status masih berupa *object* sehingga akan disesuaikan pada tahap berikutnya.

## **4. Data Preparation**

### Mengecek Data Kosong
"""

df.isna().sum()

print("Jumlah duplikasi: ", df.duplicated().sum())

"""* Tidak ada data kosong
* Tidak ada data duplikat

### Membuat dataframe baru

Kolom yang akan digunakan adalah marital status, course, daytime/evening attendance, previous qualification, previous qualification grade, mother's qualification, father's qualification, mother's occupation, father's occupation, gender, scholarship holder, age at enrollment, curricular units 1st sem approved, curricular units 1st sem grade, curricular units 2nd sem approved, curricular units 2nd sem grade, status
"""

### Menghapus kolom yang tidak diperlukan
new_df = df.drop(['Application_mode', 'Application_order', 'Nacionality', 'Admission_grade', 'Displaced', 'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date', 'International', 'Curricular_units_1st_sem_credited', 'Curricular_units_1st_sem_enrolled', 'Curricular_units_1st_sem_evaluations', 'Curricular_units_1st_sem_without_evaluations', 'Curricular_units_2nd_sem_credited', 'Curricular_units_2nd_sem_enrolled', 'Curricular_units_2nd_sem_evaluations', 'Curricular_units_2nd_sem_without_evaluations', 'Unemployment_rate', 'Inflation_rate', 'GDP'], axis=1)

new_df.head()

"""### Mengubah data 'Status' menjadi numerik

Data "Status" adalah data kategorikal: Enrolled, Graduate, Dropout.

Untuk memudahkan visualisasi data dan pembangunan model, maka data perlu diubah menjadi numerik. Maka itu, data diubah menjadi:
- Enrolled = 0
- Graduate = 1
- Dropout = 2

Hal ini akan membuat pengolahan data menjadi lebih mudah.
"""

new_df.replace(['Enrolled', 'Graduate', 'Dropout'], [0, 1, 2], inplace=True)
new_df.head()

new_df.describe()

"""## **5. Exploratory Data Analysis**

### **Business HR Dashboard**

- Link: http://localhost:3000/public/dashboard/7d5a86f7-afff-470b-b9a0-d292b4cffe34
- Email: root@mail.com
- Password: root123

### **Insight**

1. Demografi siswa:
  - Total siswa: 4424, jumlah siswa *dropout*: 1421. Maka tingkat *dropout*: (1421/4424) x 100% = 32.12%.
  - Kategori usia siswa terbesar pada rentang 17-22.5 tahun (68.87%), kedua terbesar pada rentang 22.5-30 tahun (15.05%). Data siswa *dropout* terbesar pada rentang 17-22.5 tahun (48.77%), kedua terbesar pada rentang 22.5-30 tahun (24.14%). Karena data siswa terbanyak pada rentang usia tersebut, maka data siswa *dropout* juga proporsional. Jika dilihat pada rentang 22.5-30 tahun terjadi lebih banyak siswa *dropout* kemungkinan karena faktor keluarga dan ekonomi.
  -  Jumlah siswa perempuan (64.8%) lebih tinggi dari siswa laki-laki (35.2%). Pada data siswa *dropout*, hampir sama antara siswa perempuan dan siswa laki-laki. Dapat disimpulkan bahwa siswa laki-laki beresiko lebih tinggi untuk *dropout*.
  - Jumlah siswa yang belum menikah mencapai 88.58%. Tren yang sama terlihat pada jumlah siswa yang *dropout* dimana yang belum menikah 83.32%.
  - 89.1% siswa mengambil kelas pagi. Karena data yang besar ini maka pada data siswa *dropout* juga siswa kelas pagi mencapai 85.4%.

2. *Course*:
  - *Course* yang paling banyak diambil siswa adalah *nursing* (17.31%), kemudian diikuti dengan *management, social service, veterinary nursing, journalism & communication, advertising & marketing management*, kelas sore *management, tourism, communication design, animation & multimedia design*, kelas sore *social service, agronomy, basic education, informatics engineering, equinculture*, dan lain-lain.
  - Pada data siswa *dropout*, kebanyakan berasal dari *course management* (kelas sore 9.57% dan kelas pagi 9.43%). Urutan terbesar selanjutnya adalah *course nursing, journalism & communication*, dan *tourism*. Hal ini menunjukkan bahwa angka *dropout* terbesar pada kelas *management*, terutama kelas sore *management* dimana 136 siswa dari total 268 siswa yang terdaftar.

3. Tingkat pendidikan dan pekerjaan orangtua
  - Data siswa *dropout* berdasarkan tingkat pendidikan hampir sama pada tingkat pendidikan ayah dan ibu. Kategori paling besar adalah dari tingkat pendidikan *Basic education 1st cycle (4th/5th year) or equiv.*. Kategori selanjutnya adalah *Secondary Education (12th), basic education 3rd cycle (9th/10th/11th year) or equiv, basic education 2nd cycle (6th/7th/8th year) or equiv.*. Hal ini menunjukkan latar belakang pendidikan orangtua yang hanya sampai pendidikan dasar (di bawah 12 tahun) sangat menentukan dan mempengaruhi tingkat *dropout* siswa.
  - Data siswa *dropout* berdasarkan pekerjaan juga hampir sama pada ayah dan ibu. Kategori paling besar adalah pekerja non ahli (22.73% ayah, 34.48% ibu). Hal ini menunjukkan bahwa tingkat kesadaran siswa untuk melanjutkan pendidikan sangat dipengaruhi oleh latar belakang pekerjaan orangtua. Ada kemungkinan bahwa siswa *dropout* karena tingkat sosial ekonomi orangtua dan ketidak mampuan secara ekonomi untuk melanjutkan pendidikan.

4. Tingkat pendidikan siswa dan nilai pada pendidikan yang lalu
  - Lebih dari 3/4 siswa *dropout* (75.86%) berasal dari kelompok dengan latar pendidikan SMA atau sederajat.
  - Untuk profil siswa *dropout*, meningkat pada siswa dengan nilai 90, tertinggi pada nilai 130 pada tingkat pendidikan yang lalu, kemudian menurun sampai pada nilai 190.

5. Nilai Semester 1 dan Semester 2
  - Siswa *dropout* memiliki rata-rata *curricular units approved* pada semester 1 adalah 3.59 dan 2.74 pada semester 2.
  - Siswa *dropout* tertinggi pada nilai rata-rata semester 1 di bawah 7 dan 11. Pada data nilai semester 2, jumlah siswa *dropout* tertinggi pada nilai di bawah 10.

6. Beasiswa
  - Jumlah penerima beasiswa adalah 1099 siswa dari 4244 total siswa (24.8%).
  - Dari seluruh penerima beasiswa tersebut, ada 134 siswa yang *dropout*.
  - Persentase siswa penerima beasiswa yang *dropout* adalah (134/1099)x100% = 12.19%. Persentase ini sebenarnya cukup rendah, menunjukkan bahwa beasiswa membantu siswa untuk terus dapat melanjutkan pendidikannya. Akan tetapi, perlu dilakukan telaah lebih lanjut dengan mewawancarai siswa yang menerima beasiswa namun *dropout* untuk mengetahui alasan melakukan *dropout*.

### *1. Demografi Siswa dan Status*

#### Bivariate Analysis - Status siswa berdasarkan usia
"""

fig, axes = plt.subplots(nrows=1,ncols=2, figsize=(14,6))

sns.countplot(ax=axes[0], x=df.Status, palette="Set3")
axes[0].set_title("Total Students by Status")

sns.boxplot(ax=axes[1], x=df.Status, y=df.Age_at_enrollment, palette="Set3")
axes[1].set_title("Status by Age")

import pandas as pd

# Select the relevant columns for correlation analysis
selected_columns = ['Age_at_enrollment', 'Marital_status', 'Gender', 'Daytime_evening_attendance', 'Status']

# Calculate the correlation matrix
correlation_matrix = new_df[selected_columns].corr()

# Display the correlation values with 'Status'
print(correlation_matrix['Status'])

plt.figure(figsize=(10, 8))  # Adjust figure size as needed
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix')
plt.show()

"""### *2. Status siswa berdasarkan course*"""

plt.figure(figsize=(15, 6))  # Adjust figure size as needed
sns.countplot(data=df, x='Course', hue='Status', palette='Set3')
plt.title('Student Status per Course')
plt.xlabel('Course')
plt.ylabel('Number of Students')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.legend(title='Status')
plt.tight_layout()
plt.show()

"""### *3. Hubungan antara tingkat pendidikan dan pekerjaan orang tua dengan status siswa*

#### Bivariate Analysis - Status siswa berdasarkan tingkat pendidikan dan pekerjaan orangtua
"""

# Function to create countplots for a given column
def plot_status_per_category(column_name, dataframe):
  plt.figure(figsize=(15, 6))
  sns.countplot(data=dataframe, x=column_name, hue='Status', palette='Set3',
                hue_order=['Dropout', 'Enrolled', 'Graduate'])  # Specify hue order
  plt.title(f'Student Status per {column_name}')
  plt.xlabel(column_name)
  plt.ylabel('Number of Students')
  plt.xticks(rotation=90)
  plt.legend(title='Status')
  plt.tight_layout()
  plt.show()

# Visualize status per Father's Qualification
plot_status_per_category("Fathers_qualification", df)

# Visualize status per Mother's Qualification
plot_status_per_category("Mothers_qualification", df)

# Visualize status per Father's Occupation
plot_status_per_category("Fathers_occupation", df)

# Visualize status per Mother's Occupation
plot_status_per_category("Mothers_occupation", df)

# Select the relevant columns for correlation analysis
selected_columns = ['Fathers_qualification', 'Mothers_qualification', 'Fathers_occupation', 'Mothers_occupation', 'Status']

# Calculate the correlation matrix
correlation_matrix = new_df[selected_columns].corr()

# Display the correlation values with 'Status'
print(correlation_matrix['Status'])

plt.figure(figsize=(10, 8))  # Adjust figure size as needed
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Parental Factors and Student Status')
plt.show()

"""### *4. Status siswa berdasarkan tingkat pendidikan dan nilai yang lalu*"""

plt.figure(figsize=(12, 6))
sns.boxplot(x='Status', y='Previous_qualification_grade', hue='Previous_qualification', data=df, palette='Set3')
plt.title('Student Status based on Previous Qualification and Grade')
plt.xlabel('Status')
plt.ylabel('Previous Qualification Grade')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.legend(title='Previous Qualification', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""### *5. Status siswa berdasarkan nilai pada semester 1 dan 2*"""

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot for 1st semester grades
sns.boxplot(x='Status', y='Curricular_units_1st_sem_grade', data=df, palette='Set3', ax=axes[0])
axes[0].set_title('Student Status vs. 1st Semester Grade')
axes[0].set_xlabel('Status')
axes[0].set_ylabel('1st Semester Grade')

# Plot for 2nd semester grades
sns.boxplot(x='Status', y='Curricular_units_2nd_sem_grade', data=df, palette='Set3', ax=axes[1])
axes[1].set_title('Student Status vs. 2nd Semester Grade')
axes[1].set_xlabel('Status')
axes[1].set_ylabel('2nd Semester Grade')

plt.tight_layout()
plt.show()

"""### *6. Hubungan antara beasiswa dengan status siswa*"""

plt.figure(figsize=(8, 6))
sns.countplot(x='Status', hue='Scholarship_holder', data=df, palette='Set3')
plt.title('Student Status vs. Scholarship Holder')
plt.xlabel('Status')
plt.ylabel('Number of Students')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Scholarship Holder', labels=['No', 'Yes'])
plt.tight_layout()
plt.show()

"""## **6. Data Preprocessing**

### Train-Test-Split

Membagi dataset menjadi data latih (train) dan data uji (test) dengan perbandingan 80:20. Ratio ini dianggap cukup karena besar data total yang adalah 4424. Selain itu, ratio ini memberikan nilai accuracy yang lebih baik pada data test, dikarenakan jumlah data test cukup besar dan model tidak overfitting.
"""

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(new_df, test_size=0.2, random_state=42, shuffle=True)
train_df.reset_index(drop=True, inplace=True)
test_df.reset_index(drop=True, inplace=True)

print(train_df.shape)
print(test_df.shape)

"""### Melihat Sebaran Data"""

train_df.Status.value_counts()

sns.countplot(data=train_df, x="Status", palette="Set3")
plt.title("Total Students by Status")
plt.xlabel("Status")
plt.ylabel("Number of Students")
plt.show()

"""Pada dataframe train didapatkan:

*   Data siswa enrolled = 643 siswa
*   Data siswa graduate = 1791 siswa
*   Data siswa dropout = 1105 siswa

Berdasarkan data tersebut, maka kita perlu melakukan oversampling agar data berimbang.

### Oversampling
"""

from sklearn.utils import resample
from sklearn.utils import shuffle

df_majority_1 = train_df[(train_df['Status'] == 1)]
df_majority_2 = train_df[(train_df['Status'] == 2)]
df_minority = train_df[(train_df['Status'] == 0)]

df_majority_2_undersampled = resample(df_majority_2, n_samples=1791, random_state=42)
df_minority_undersampled = resample(df_minority, n_samples=1791, random_state=42)

oversampled_train_df = pd.concat([df_majority_1, df_majority_2_undersampled]).reset_index(drop=True)
oversampled_train_df = pd.concat([oversampled_train_df, df_minority_undersampled]).reset_index(drop=True)
oversampled_train_df = shuffle(oversampled_train_df, random_state=42)
oversampled_train_df.reset_index(drop=True, inplace=True)

sns.countplot(data=oversampled_train_df, x="Status")
plt.show()

"""### Membagi data menjadi fitur X dan y

y adalah target yaitu Status dan X adalah fitur lain seperti 'Marital_status', 'Course', 'Daytime_evening_attendance', 'Previous_qualification', 'Previous_qualification_grade', 'Mothers_qualification', 'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation', 'Gender', 'Scholarship_holder', 'Age_at_enrollment', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade'.
"""

X_train = oversampled_train_df.drop(columns="Status", axis=1)
y_train = oversampled_train_df["Status"]

X_test = test_df.drop(columns="Status", axis=1)
y_test = test_df["Status"]

"""### Encoding & Scaling

Scaling membantu membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma sehingga hasil model akan lebih baik. Langkah selanjutnya adalah melakukan standarisasi pada fitur numerik dengan menggunakan teknik StandardScaler dari library Scikitlearn. Hal ini dilakukan karena skala variabel yang berbeda-beda dari setiap fitur yang ada dalam dataset.
"""

import pandas as pd

def one_hot_encoding_categorical_features(df, columns):
  """Performs one-hot encoding for specified categorical columns.

  Args:
    df: The input DataFrame.
    columns: A list of categorical columns to be encoded.

  Returns:
    A DataFrame with one-hot encoded columns.
  """

  # Create a copy of the DataFrame to avoid modifying the original
  encoded_df = df.copy()

  # Iterate through the specified columns
  for column in columns:
    # Perform one-hot encoding using pandas' get_dummies()
    dummies = pd.get_dummies(encoded_df[column], prefix=column)

    # Concatenate the encoded columns to the DataFrame
    encoded_df = pd.concat([encoded_df, dummies], axis=1)

    # Drop the original categorical column
    encoded_df.drop(columns=[column], inplace=True)

  return encoded_df

# Specify the columns to be one-hot encoded
columns_to_encode = ['Marital_status', 'Previous_qualification', 'Course']

# Perform one-hot encoding on X_train and X_test
X_train_encoded = one_hot_encoding_categorical_features(X_train, columns_to_encode)
X_test_encoded = one_hot_encoding_categorical_features(X_test, columns_to_encode)

import os
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
import joblib

def scaling(features, df, df_test=None):
    # Create the 'model' directory if it doesn't exist
    if not os.path.exists("model"):
        os.makedirs("model")

    if df_test is not None:
        df = df.copy()
        df_test = df_test.copy()
        for feature in features:
            scaler = MinMaxScaler()
            X = np.asanyarray(df[feature])
            X = X.reshape(-1,1)
            scaler.fit(X)
            df["{}".format(feature)] = scaler.transform(X)
            joblib.dump(scaler, "model/scaler_{}.joblib".format(feature))

            X_test = np.asanyarray(df_test[feature])
            X_test = X_test.reshape(-1,1)
            df_test["{}".format(feature)] = scaler.transform(X_test)
        return df, df_test
    else:
        df = df.copy()
        for feature in features:
            scaler = MinMaxScaler()
            X = np.asanyarray(df[feature])
            X = X.reshape(-1,1)
            scaler.fit(X)
            df["{}".format(feature)] = scaler.transform(X)
            joblib.dump(scaler, "model/scaler_{}.joblib".format(feature))
        return df

def encoding(features, df, df_test=None):
    if df_test is not None:
        df = df.copy()
        df_test = df_test.copy()
        for feature in features:
            encoder = LabelEncoder()
            # Use pd.concat to combine the Series instead of append
            encoder.fit(pd.concat([df[feature], df_test[feature]]).unique())
            df["{}".format(feature)] = encoder.transform(df[feature])
            joblib.dump(encoder, "model/encoder_{}.joblib".format(feature))

            df_test["{}".format(feature)] = encoder.transform(df_test[feature])
        return df, df_test
    else:
        df = df.copy()
        for feature in features:
            encoder = LabelEncoder()
            encoder.fit(df[feature])
            df["{}".format(feature)] = encoder.transform(df[feature])
            joblib.dump(encoder, "model/encoder_{}.joblib".format(feature))
        return df

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
import joblib

# Create a OneHotEncoder object
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # sparse=False for array output

# Fit the encoder to the categorical columns
encoder.fit(df[['Marital_status', 'Course', 'Previous_qualification']])

# Save the encoder using joblib
joblib.dump(encoder, 'model/onehot_encoder.joblib')

numerical_columns = [
    'Age_at_enrollment',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Previous_qualification_grade',
]

categorical_columns = [
    # The following columns have already been one-hot encoded
    # 'Marital_status', 'Course', 'Previous_qualification',
    'Daytime_evening_attendance',
    'Mothers_qualification',
    'Fathers_qualification',
    'Mothers_occupation',
    'Fathers_occupation',
    'Gender',
    'Scholarship_holder',
]

new_train_df, new_test_df = scaling(numerical_columns, X_train_encoded, X_test_encoded)
new_train_df, new_test_df = encoding(categorical_columns, new_train_df, new_test_df)

encoder = LabelEncoder()
encoder.fit(y_train)
new_y_train = encoder.transform(y_train)
joblib.dump(encoder, "model/encoder_target.joblib")

new_y_test = encoder.transform(y_test)

"""### Principal Component Analysis"""

pca_numerical_columns = [
    'Age_at_enrollment',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
]

train_pca_df = new_train_df.copy().reset_index(drop=True)
test_pca_df = new_test_df.copy().reset_index(drop=True)

from sklearn.decomposition import PCA

pca = PCA(n_components=len(pca_numerical_columns), random_state=123)
pca.fit(train_pca_df[pca_numerical_columns])
princ_comp = pca.transform(train_pca_df[pca_numerical_columns])

var_exp = pca.explained_variance_ratio_.round(3)
cum_var_exp = np.cumsum(var_exp)

plt.bar(range(len(pca_numerical_columns)), var_exp, alpha=0.5, align='center', label='individual explained variance')
plt.step(range(len(pca_numerical_columns)), cum_var_exp, where='mid', label='cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
plt.legend(loc='best')
plt.show()

pca_1 = PCA(n_components=3, random_state=123)
pca_1.fit(train_pca_df[pca_numerical_columns])
joblib.dump(pca_1, "model/pca_{}.joblib".format(1))
princ_comp_1 = pca_1.transform(train_pca_df[pca_numerical_columns])
train_pca_df[["pc1_1", "pc1_2", "pc1_3"]] = pd.DataFrame(princ_comp_1, columns=["pc1_1", "pc1_2", "pc1_3"])
train_pca_df.drop(columns=pca_numerical_columns, axis=1, inplace=True)
train_pca_df.head()

test_princ_comp_1 = pca_1.transform(test_pca_df[pca_numerical_columns]) # Use the original pca_numerical_columns
test_pca_df[["pc1_1", "pc1_2", "pc1_3"]] = pd.DataFrame(test_princ_comp_1, columns=["pc1_1", "pc1_2", "pc1_3"])
test_pca_df.drop(columns=pca_numerical_columns, axis=1, inplace=True) # Use the original pca_numerical_columns
test_pca_df.head()

"""## **7. Model Development**

### **1. Grid Search**
*Hyperparameter tuning* adalah proses menemukan kombinasi terbaik untuk mengoptimalkan performa model. *Grid search* adalah teknik klasik yang dapat digunakan untuk *hyperparameter tuning* tersebut. Proses dimulai dengan menentukan grid dari beberapa kombinasi nilai *hyperparameter*. Proses selanjutnya adalah melatih dan mengevaluasi model dari masing-masing kombinasi. Setelah itu, kombinasi terbaik akan dipilih berdasarkan metrik.

Keuntungan menggunakan *Grid Search*: Dapat menemukan kombinasi terbaik dari beberapa *hyperparameter* dalam *grid*. Selain itu, konsep ini cukup lugas dan dapat dipakai pada *library machine learning*.

Kelemahan *Grid Search*: membutuhkan waktu yang lama jika terdapat banyak kombinasi *hyperparameter*.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

param_grid = {
    "penalty": ["l1","l2"],
    "C": [0.01, 0.1, 1]
}

log_model = LogisticRegression(random_state=123)

CV_lr = GridSearchCV(estimator=log_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_lr.fit(train_pca_df, new_y_train)

"""### **2. Decision Tree Classifier**
Decision tree adalah algoritma yang membuat keputusan dengan membagi data ke subset berdasarkan fitur yang ada. Sama seperti sebuah pohon, node/persimpangan melambangkan keputusan, cabang melambangkan hasil dan daun (leaf node) melambangkan prediksi akhir (class label).

Keuntungan Decision Tree adalah mudah dimengerti dan divisualisasikan sehingga cocok untuk menjelaskan proses membuat keputusan. Decision Tree juga mampu menangkap hubungan non linear antara variabel fitur dan target. Decision Tree juga dapat diaplikasikan pada data numerik maupun kategorikal.

Kelemahan Decision Tree adalah mudah menjadi overfitting sehingga prediksi jadi tidak akurat, serta ketidakstabilan jika ada perubahan data. Perubahan data sekecil apapun akan membawa kepada perubahan signifikan pada struktur tree.
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

tree_model = DecisionTreeClassifier(random_state=123)

param_grid = {
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [5, 6, 7, 8],
    'criterion' :['gini', 'entropy']
}

CV_tree = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_tree.fit(train_pca_df, new_y_train)

print("best parameters: ", CV_tree.best_params_)

tree_model = DecisionTreeClassifier(
    random_state=123,
    criterion='gini',
    max_depth=8,
    max_features='sqrt'
)

tree_model.fit(train_pca_df, new_y_train)
joblib.dump(tree_model, "model/tree_model.joblib")

"""### **3. Random Forest Classifier**

Algoritma random forest adalah salah satu algoritma supervised learning. Ia dapat digunakan untuk menyelesaikan masalah klasifikasi dan regresi. Random forest merupakan model prediksi yang terdiri dari beberapa model dan bekerja secara bersama-sama. Random forest menggabungkan banyak model sederhana ini menjadi satu model yang lebih kuat. Model-model sederhana yang digunakan dalam random forest biasanya adalah Decision Tree.

Keuntungan dari Random Forest adalah menghasilkan prediksi yang lebih akurat dibandingkan dengan model tunggal, karena menggabungkan banyak decision tree.
Model random forest cenderung lebih stabil dan tidak mudah overfitting. Random forest dapat bekerja dengan baik pada data numerik maupun kategorikal, serta dapat menangani data yang memiliki missing values. Random forest dapat memberikan informasi tentang pentingnya setiap fitur dalam memprediksi target variabel, serta dapat diterapkan pada dataset yang besar dan kompleks.
"""

from sklearn.ensemble import RandomForestClassifier

rdf_model = RandomForestClassifier(random_state=123)

param_grid = {
    'n_estimators': [200, 500],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [6, 7, 8],
    'criterion' :['gini', 'entropy']
}

CV_rdf = GridSearchCV(estimator=rdf_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_rdf.fit(train_pca_df, new_y_train)

print("best parameters: ", CV_rdf.best_params_)

rdf_model = RandomForestClassifier(
    random_state=123,
    max_depth=8,
    n_estimators=500,
    max_features='log2',
    criterion='entropy',
    n_jobs=-1
)
rdf_model.fit(train_pca_df, new_y_train)
joblib.dump(rdf_model, "model/rdf_model.joblib")

"""### **4. Gradient Boost Classifier**

Gradient boosting menggunakan decision tree sebagai dasar dari modelnya. GBoost menggunakan framework gradient boosting dimana setiap tree baru dilatih untuk mengoreksi error pada tree sebelumnya. Proses iteratif ini akan meningkatkan performa secara keseluruhan. GBoost juga menggunakan teknik regularisasi untuk mencegah overfitting. GBoost juga sangat scalable serta memiliki mekanisme untuk mengatasi permasalahan missing values selama training.

Kelemahan dari GBoost adalah kompleksitas dan kesulitan untuk menginterpretasikan keputusan/prediksi yang dibuat oleh model.
"""

from sklearn.ensemble import GradientBoostingClassifier

gboost_model = GradientBoostingClassifier(random_state=123)

param_grid = {
    'max_depth': [5, 8],
    'n_estimators': [200, 300],
    'learning_rate': [0.01, 0.1],
    'max_features': ['auto', 'sqrt', 'log2']
}

CV_gboost = GridSearchCV(estimator=gboost_model, param_grid=param_grid, cv=5, n_jobs=-1)
CV_gboost.fit(train_pca_df, new_y_train)

print("best parameters: ", CV_gboost.best_params_)

gboost_model = GradientBoostingClassifier(
    random_state=123,
    learning_rate=0.1,
    max_depth=8,
    max_features='sqrt',
    n_estimators=200
)
gboost_model.fit(train_pca_df, new_y_train)
joblib.dump(gboost_model, "model/gboost_model.joblib")

"""## **8. Model Evaluation menggunakan confusion matrix**

*Confusion matrix* memberikan gambaran performa model pada setiap kelas. Ia menunjukkan berapa banyak prediksi benar dan prediksi salah. Berdasarkan hasil di atas, kita dapat melihat seberapa baik performa model untuk melakukan prediksi pada setiap kelas atau label. Hal ini akan sangat berguna terutama ketika berhadapan dengan data yang memiliki kelas tidak seimbang (imbalance data). Selain itu, hasil dari confusion matrix ini akan digunakan untuk menghitung berbagai metrik lain seperti accuracy, precision, dll.

Rumus metrik *accuracy*:
Accuracy = (True A + True B + True C)/ (True A + True B + True C + False A + False B + False C)

Rumus metrik *precision*:
Precision = True A/(True A + False A)

Rumus metrik *recall*:
Recall = True A/(True A + False B + False C)
"""

from sklearn.metrics import classification_report, confusion_matrix

def evaluating(y_pred, y_true):
    '''Evaluasi model'''
    # labels = ['Enrolled', 'Graduate', 'Dropout']
    labels = [0, 1, 2]

    print(classification_report(y_pred=y_pred, y_true=y_true))

    cnf_matrix = confusion_matrix(y_pred=y_pred, y_true=y_true, labels=labels)
    confusion_matrix_df = pd.DataFrame(cnf_matrix, labels, labels)
    sns.heatmap(confusion_matrix_df, annot=True, annot_kws={'size': 14}, fmt='d', cmap='YlGnBu')
    plt.ylabel('True label', fontsize=15)
    plt.xlabel('Predicted label', fontsize=15)
    plt.show()

    return confusion_matrix_df

# Get missing columns in test_pca_df
missing_cols = set(train_pca_df.columns) - set(test_pca_df.columns)

# Add missing columns to test_pca_df with 0 values
for col in missing_cols:
    test_pca_df[col] = 0

# Ensure the order of columns in test_pca_df is the same as in train_pca_df
test_pca_df = test_pca_df[train_pca_df.columns]

# Now you can predict using the modified test_pca_df
y_pred_test = tree_model.predict(test_pca_df)
y_pred_test = encoder.inverse_transform(y_pred_test)

evaluating(y_pred=y_pred_test, y_true=y_test)

### evaluasi model random forest
y_pred_test = rdf_model.predict(test_pca_df)
y_pred_test = encoder.inverse_transform(y_pred_test)

evaluating(y_pred=y_pred_test, y_true=y_test)

y_pred_test = gboost_model.predict(test_pca_df)
y_pred_test = encoder.inverse_transform(y_pred_test)

evaluating(y_pred=y_pred_test, y_true=y_test)

"""> Dari hasil di atas, didapatkan bahwa model Gradient Boosting lebih baik dalam memprediksi dimana hasil accuracy yang lebih baik. Dengan demikian, model Gradient Boosting yang akan digunakan sebagai model machine learning untuk memprediksi tingkat dropout siswa."""

joblib.dump(gboost_model, "model/gboost_model.joblib")

def plot_feature_importances(feature_importances, cols):
    features = pd.DataFrame(feature_importances, columns=['coef_value']).set_index(cols)
    features = features.sort_values(by='coef_value', ascending=False)
    top_features = features

    plt.figure(figsize=(10, 6))
    sns.barplot(x='coef_value', y=features.index, data=features)
    plt.show()
    return top_features

plot_feature_importances(gboost_model.feature_importances_, train_pca_df.columns)

"""## **9. Kesimpulan**

1. Demografi siswa mempengaruhi tingkat *dropout*.
  - tingkat *dropout* tertinggi pada rentang usia 17-30 tahun.
  - tingkat *dropout* hampir sama antara laki-laki dan perempuan. Akan tetapi jumlah siswa perempuan jauh lebih banyak sehingga dapat disimpulkan bahwa laki-laki lebih beresiko *droput*.
  - tingkat *dropout* tertinggi pada siswa yang belum menikah karena memang sebagian besar demografi siswa adalah belum menikah.
  - tingkat *dropout* sesuai kelas pagi/sore berbanding lurus dengan jumlah siswa pada kelas pagi/sore.

2. Tingkat *dropout* berdasarkan *course*.
  - Jumlah *course* yang paling banyak diambil oleh siswa adalah *nursing*.
  - Tingkat *dropout* ada pada *course management* baik pada kelas pagi maupun sore.
  - Kelas sore *management* memiliki tingkat *dropout* sebesar: (136/268)x100% = 50.75%.

3. Tingkat pendidikan dan pekerjaan orangtua mempengaruhi *dropout*.
  - Rata-rata siswa yang *dropout*, data pendidikan orangtua adalah di tingkat *basic education* yakni lulusan SD, SMP, atau SMA.
  - Pekerjaan orangtua juga mempengaruhi tingkat *dropout*, didapatkan pada data bahwa kebanyakan siswa *dropout* memiliki orangtua dengan latar belakang pekerja non-ahli.
  - Rendahnya tingkat pendidikan orangtua dan pekerjaan orangtua membuat permasalahan sosial ekonomi sehingga siswa kesulitan melanjutkan ke tingkat pendidikan yang lebih tinggi.

4. Profil siswa *dropout* berdasarkan nilai dan tingkat pendidikan yang lalu
  - Kebanyakan siswa *dropout* memiliki latar belakang pendidikan dari SMA atau setingkat.
  - Tingkat *dropout* meningkat dari nilai siswa 90-130, kemudian menurun kembali sampai nilai 190.

5. Profil siswa *dropout* berdasarkan nilai di semester satu dan dua
  - Pada semester 1 dan semester 2, kebanyakan siswa *dropout* pada nilai di bawah 12.5

6. Pengaruh beasiswa dengan tingkat *dropout*
  - Persentase siswa penerima beasiswa yang *dropout* adalah (134/1099)x100% = 12.19%. Persentase ini sebenarnya cukup rendah, menunjukkan bahwa beasiswa membantu siswa untuk terus dapat melanjutkan pendidikannya. Akan tetapi, perlu dilakukan telaah lebih lanjut dengan mewawancarai siswa yang menerima beasiswa namun *dropout* untuk mengetahui alasan melakukan *dropout*.

## **10. Rekomendasi Action Items**

**1. Academic Support**
  - Program intervensi dini: Mengidentifikasi siswa yang beresiko *dropout* sedini mungkin (misal: berdasarkan usia dan/atau nilai pada semester lalu) serta membuat program seperti *tutoring, mentoring, and counseling*.
  - Meningkatkan performa akademik: membuat program seperti *workshops* atau menyediakan *resources* untuk meningkatkan cara belajar, manajemen waktu, atau strategi menghadapi ujian.
  - *Flexible Curriculum*: Menyediakan program yang lebih fleksibel seperti kelas online, akselerasi, dan lain sebagainya. Selain itu, dapat juga dibangun sistem belajar personal yang sesuai dengan kebutuhan masing-masing siswa sehingga mereka dapat belajar sesuai kecepatan mereka masing-masing.
  - Dukungan bagi siswa bermasalah: Mengimplementasikan program dukungan bagi siswa yang sering absen atau yang memiliki nilai yang rendah.

**2. Financial Support**
  - Bantuan finansial: menyediakan informasi dan bantuan untuk siswa dapat mendapatkan beasiswa atau bantuan keuangan lainnya.
  - Mengetahui halangan finansial: menawarkan program bantuan keuangan untuk siswa yang mengalami masalah finansial sementara.
  - Program belajar sambil bekerja: menciptakan peluang melalui program siswa bekerja melalui kerjasama dengan dunia usaha sehingga siswa dapat memperoleh pengalaman sambil mendapatkan uang untuk biaya kuliah/hidup lainnya.

**3. Social and Emotional Support**
  - Meningkatkan rasa kepemilikan: membangun dan memelihara suasana belajar yang kondusif dan suportif dimana siswa merasa dihargai dan didukung.
  - *Peer mentoring*: melibatkan siswa untuk membentuk grup belajar.
  - *Counseling service*: memberikan layanan konseling bagi siswa untuk memenuhi kebutuhan personal, sosial dan emosional siswa.

**4. Institutional Actions**
  - Meningkatkan *data tracking*: mengimplementasikan sistem untuk melacak progres siswa serta memprediksi *dropout* siswa.
  - *Regular Check-In*: melakukan pendekatan secara rutin kepada siswa beresiko.
  - *Exit Interview*: melakukan tanya jawab dengan siswa yang memutuskan *dropout* untuk menggali alasan serta mendapatkan data.

## **Referensi (APA Style)**
1. Dealls (2025). Drop Out: Arti, Faktor Penyebab & Dampaknya! | Dealls. [online] Dealls. Available at: https://dealls.com/pengembangan-karir/drop-out-artinya.
2. Hakim, A. (2020). FAKTOR PENYEBAB ANAK PUTUS SEKOLAH. Jurnal Pendidikan, 21(2), pp.122–132. doi:https://doi.org/10.33830/jp.v21i2.907.2020.
3. Hidayat, M. Mahaputra & Purwitasari, Diana & Ginardi, R.V.Hari. (2013). ANALISIS PREDIKSI DROP OUT BERDASARKAN PERILAKU SOSIAL MAHASISWA DALAM EDUCATIONAL DATA MINING MENGGUNAKAN JARINGAN SYARAF TIRUAN. IPTEK ITATS.
"""

pip freeze > requirements.txt