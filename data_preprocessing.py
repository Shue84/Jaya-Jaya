# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeiWSJriHUBRY9ULtBpS8pOwVhgP1emy
"""

import joblib
import numpy as np
import pandas as pd

onehot_encoder = joblib.load('model/onehot_encoder.joblib')
encoder_Daytime_evening_attendance = joblib.load('model/encoder_Daytime_evening_attendance.joblib')
encoder_Fathers_occupation = joblib.load('model/encoder_Fathers_occupation.joblib')
encoder_Fathers_qualification = joblib.load('model/encoder_Fathers_qualification.joblib')
encoder_Gender = joblib.load('model/encoder_Gender.joblib')
encoder_Mothers_occupation = joblib.load('model/encoder_Mothers_occupation.joblib')
encoder_Mothers_qualification = joblib.load('model/encoder_Mothers_qualification.joblib')
encoder_Scholarship_holder = joblib.load('model/encoder_Scholarship_holder.joblib')
pca_1 = joblib.load('model/pca_1.joblib')
scaler_Age_at_enrollment = joblib.load('model/scaler_Age_at_enrollment.joblib')
scaler_Curricular_units_1st_sem_approved = joblib.load('model/scaler_Curricular_units_1st_sem_approved.joblib')
scaler_Curricular_units_1st_sem_grade = joblib.load('model/scaler_Curricular_units_1st_sem_grade.joblib')
scaler_Curricular_units_2nd_sem_approved = joblib.load('model/scaler_Curricular_units_2nd_sem_approved.joblib')
scaler_Curricular_units_2nd_sem_grade = joblib.load('model/scaler_Curricular_units_2nd_sem_grade.joblib')
scaler_Previous_qualification_grade = joblib.load('model/scaler_Previous_qualification_grade.joblib')

pca_numerical_columns = [
    'Age_at_enrollment',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Previous_qualification_grade'
]
# Define the correct order of columns for one-hot encoding
onehot_encoded_columns = ['Marital_status', 'Course', 'Previous_qualification']

def data_preprocessing(data):
    """Preprocessing data

    Args:
        data (Pandas DataFrame): Dataframe that contain all the data to make prediction

    return:
        Pandas DataFrame: Dataframe that contain all the preprocessed data
    """
    data = data.copy()
    df = pd.DataFrame()

    # Handle NaNs in numerical columns
    for col in pca_numerical_columns:
        if data[col].isnull().any():
            print(f"NaNs found in {col} before imputation.")
            data[col] = data[col].fillna(0 if len(data) == 1 else data[col].mean())
            print(f"NaNs in {col} after imputation: {data[col].isnull().sum()}")
        else:
            print(f"No NaNs in {col} before imputation.")

    # Scale numerical features
    scaler_dict = {
        'Age_at_enrollment': scaler_Age_at_enrollment,
        'Curricular_units_1st_sem_approved': scaler_Curricular_units_1st_sem_approved,
        'Curricular_units_1st_sem_grade': scaler_Curricular_units_1st_sem_grade,
        'Curricular_units_2nd_sem_approved': scaler_Curricular_units_2nd_sem_approved,
        'Curricular_units_2nd_sem_grade': scaler_Curricular_units_2nd_sem_grade,
        'Previous_qualification_grade': scaler_Previous_qualification_grade,
    }

    for col in pca_numerical_columns:
        print(f"--- Scaling column: {col} ---")
        print("Data type before scaling:", data[col].dtype)
        print("Shape before scaling:", data[col].shape)
        print("NaNs before scaling:", data[col].isnull().sum())
        print("Example values before scaling:\n", data[col].head(10))

        if len(data[col].shape) == 1:
            data[[col]] = scaler_dict[col].transform(np.array(data[col]).reshape(-1, 1))
        elif len(data[col].shape) == 2:
            data[[col]] = scaler_dict[col].transform(data[[col]])
        else:
            print(f"Unexpected shape for {col}: {data[col].shape}. Skipping scaling.")
            continue

        print("Data type after scaling:", data[col].dtype)
        print("Shape after scaling:", data[col].shape)
        print("NaNs after scaling:", data[col].isnull().sum())
        print("Example values after scaling:\n", data[col].head(10))
        print("--- End scaling column: {col} ---")

    # One-hot encode categorical features
    encoded_cols = onehot_encoder.transform(data[onehot_encoded_columns])
    encoded_feature_names = onehot_encoder.get_feature_names_out(onehot_encoded_columns)
    encoded_df = pd.DataFrame(encoded_cols, index=data.index, columns=encoded_feature_names)

    # Ensure all expected columns are present
    for col in onehot_encoder.get_feature_names_out():
        if col not in encoded_df.columns:
            encoded_df[col] = 0  # add missing column

    # Reorder columns to match training time
    encoded_df = encoded_df[encoded_feature_names]

    df = pd.concat([df, encoded_df], axis=1)

   # Encode the other categorical features
    df['Daytime_evening_attendance'] = encoder_Daytime_evening_attendance.transform(data['Daytime_evening_attendance'])
    df['Fathers_occupation'] = encoder_Fathers_occupation.transform(data['Fathers_occupation'])
    df['Fathers_qualification'] = encoder_Fathers_qualification.transform(data['Fathers_qualification'])
    df['Gender'] = encoder_Gender.transform(data['Gender'])
    df['Mothers_occupation'] = encoder_Mothers_occupation.transform(data['Mothers_occupation'])
    df['Mothers_qualification'] = encoder_Mothers_qualification.transform(data['Mothers_qualification'])
    df['Scholarship_holder'] = encoder_Scholarship_holder.transform(data['Scholarship_holder'])

   # PCA: ensure column names and order match exactly
    expected_pca_features = pca_1.feature_names_in_
    missing_cols = set(expected_pca_features) - set(data.columns)
    extra_cols = set(data.columns) - set(expected_pca_features)

    if missing_cols:
        raise ValueError(f"Missing columns for PCA: {missing_cols}")
    if extra_cols:
        print(f"Warning: Extra columns not used in PCA: {extra_cols}")

    X_pca_input = data[expected_pca_features].astype(np.float64)
    pca_transformed = pca_1.transform(X_pca_input)

    pca_columns = ['pc1_1', 'pc1_2', 'pc1_3']
    pca_df = pd.DataFrame(pca_transformed, index=data.index, columns=pca_columns)
    df = pd.concat([df, pca_df], axis=1)

    return df
