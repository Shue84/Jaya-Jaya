# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeiWSJriHUBRY9ULtBpS8pOwVhgP1emy
"""

import joblib
import numpy as np
import pandas as pd

onehot_encoder = joblib.load('model/onehot_encoder.joblib')
encoder_Daytime_evening_attendance = joblib.load('model/encoder_Daytime_evening_attendance.joblib')
encoder_Fathers_occupation = joblib.load('model/encoder_Fathers_occupation.joblib')
encoder_Fathers_qualification = joblib.load('model/encoder_Fathers_qualification.joblib')
encoder_Gender = joblib.load('model/encoder_Gender.joblib')
encoder_Mothers_occupation = joblib.load('model/encoder_Mothers_occupation.joblib')
encoder_Mothers_qualification = joblib.load('model/encoder_Mothers_qualification.joblib')
encoder_Scholarship_holder = joblib.load('model/encoder_Scholarship_holder.joblib')
pca_1 = joblib.load('model/pca_1.joblib')
scaler_Age_at_enrollment = joblib.load('model/scaler_Age_at_enrollment.joblib')
scaler_Curricular_units_1st_sem_approved = joblib.load('model/scaler_Curricular_units_1st_sem_approved.joblib')
scaler_Curricular_units_1st_sem_grade = joblib.load('model/scaler_Curricular_units_1st_sem_grade.joblib')
scaler_Curricular_units_2nd_sem_approved = joblib.load('model/scaler_Curricular_units_2nd_sem_approved.joblib')
scaler_Curricular_units_2nd_sem_grade = joblib.load('model/scaler_Curricular_units_2nd_sem_grade.joblib')
scaler_Previous_qualification_grade = joblib.load('model/scaler_Previous_qualification_grade.joblib')

pca_numerical_columns = [
    'Age_at_enrollment',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Previous_qualification_grade'
]
# Define the correct order of columns for one-hot encoding
onehot_encoded_columns = ['Marital_status', 'Course', 'Previous_qualification']
all_onehot_cols = onehot_encoder.get_feature_names_out(onehot_encoded_columns)  # Store original columns
expected_pca_features = pca_1.feature_names_in_ #Store original PCA features

def data_preprocessing(data):
    """Preprocessing data

    Args:
        data (Pandas DataFrame): Dataframe that contain all the data to make prediction

    return:
        Pandas DataFrame: Dataframe that contain all the preprocessed data
    """
    data = data.copy()
    df = pd.DataFrame()

    print("--- Initial Data Info ---")
    print("Data shape:", data.shape)
    print("Data columns:\n", data.columns)

    # Handle NaNs in numerical columns
    for col in pca_numerical_columns:
        if data[col].isnull().any():
            print(f"NaNs found in {col} before imputation.")
            data[col] = data[col].fillna(0 if len(data) == 1 else data[col].mean())
            print(f"NaNs in {col} after imputation: {data[col].isnull().sum()}")
        else:
            print(f"No NaNs in {col} before imputation.")

    # Scale numerical features
    scaler_dict = {
        'Age_at_enrollment': scaler_Age_at_enrollment,
        'Curricular_units_1st_sem_approved': scaler_Curricular_units_1st_sem_approved,
        'Curricular_units_1st_sem_grade': scaler_Curricular_units_1st_sem_grade,
        'Curricular_units_2nd_sem_approved': scaler_Curricular_units_2nd_sem_approved,
        'Curricular_units_2nd_sem_grade': scaler_Curricular_units_2nd_sem_grade,
        'Previous_qualification_grade': scaler_Previous_qualification_grade,
    }

    for col in pca_numerical_columns:
        print(f"--- Scaling column: {col} ---")
        print("Data type before scaling:", data[col].dtype)
        print("Shape before scaling:", data[col].shape)
        print("NaNs before scaling:", data[col].isnull().sum())
        print("Example values before scaling:\n", data[col].head(10))

        if len(data[col].shape) == 1:
            data[[col]] = scaler_dict[col].transform(np.array(data[col]).reshape(-1, 1))
        elif len(data[col].shape) == 2:
            data[[col]] = scaler_dict[col].transform(data[[col]])
        else:
            print(f"Unexpected shape for {col}: {data[col].shape}. Skipping scaling.")
            continue

        print("Data type after scaling:", data[col].dtype)
        print("Shape after scaling:", data[col].shape)
        print("NaNs after scaling:", data[col].isnull().sum())
        print("--- End scaling column: {col} ---")

    # One-hot encode categorical features
    print("--- Before One-Hot Encoding ---")
    print("Shape before encoding:", data.shape)
    print("Columns before encoding:\n", data.columns)

   # One-hot encode categorical features
    encoded_cols = onehot_encoder.transform(data[onehot_encoded_columns])
    encoded_df = pd.DataFrame(encoded_cols, index=data.index, columns=onehot_encoder.get_feature_names_out(onehot_encoded_columns))

    print("--- After Initial One-Hot Encoding ---")
    print("Shape after initial encoding:", encoded_df.shape)
    print("Columns after initial encoding:\n", encoded_df.columns)

    # Ensure *all* original one-hot encoded columns are present, in the correct order
    for col in all_onehot_cols:
        if col not in encoded_df.columns:
            encoded_df[col] = 0  # Add missing column
    encoded_df = encoded_df[all_onehot_cols]  # Reorder to match training

    print("--- After Ensuring All One-Hot Columns ---")
    print("Shape after ensuring all columns:", encoded_df.shape)
    print("Columns after ensuring all columns:\n", encoded_df.columns)
    
    df = pd.concat([df, encoded_df], axis=1)

    print("--- After Concatenating One-Hot ---")
    print("Shape after concatenating:", df.shape)
    print("Columns after concatenating:\n", df.columns)

   # Encode the other categorical features
    df['Daytime_evening_attendance'] = encoder_Daytime_evening_attendance.transform(data['Daytime_evening_attendance'])
    df['Fathers_occupation'] = encoder_Fathers_occupation.transform(data['Fathers_occupation'])
    df['Fathers_qualification'] = encoder_Fathers_qualification.transform(data['Fathers_qualification'])
    df['Gender'] = encoder_Gender.transform(data['Gender'])
    df['Mothers_occupation'] = encoder_Mothers_occupation.transform(data['Mothers_occupation'])
    df['Mothers_qualification'] = encoder_Mothers_qualification.transform(data['Mothers_qualification'])
    df['Scholarship_holder'] = encoder_Scholarship_holder.transform(data['Scholarship_holder'])

    print("--- After Other Categorical Encoding ---")
    print("Shape after other encoding:", df.shape)
    print("Columns after other encoding:\n", df.columns)

   # PCA: ensure column names and order match exactly
    print("Expected PCA features:", expected_pca_features)
    print("Data columns before PCA:\n", data.columns)
    
    missing_cols = set(expected_pca_features) - set(data.columns)
    extra_cols = set(data.columns) - set(expected_pca_features)

    if missing_cols:
        raise ValueError(f"Missing columns for PCA: {missing_cols}")
    if extra_cols:
        print(f"Warning: Extra columns not used in PCA: {extra_cols}")

    X_pca_input = data[pca_numerical_columns].copy()  # Create PCA input
    print("--- Before PCA ---")
    print("Shape of X_pca_input:", X_pca_input.shape)
    print("NaNs in X_pca_input:\n", X_pca_input.isnull().sum())
    print("PCA input columns:\n", X_pca_input.columns)

    pca_transformed = pca_1.transform(X_pca_input)

    pca_columns = ['pc1_1', 'pc1_2', 'pc1_3']  # Use the correct names!
    pca_df = pd.DataFrame(pca_transformed, index=data.index, columns=pca_columns)

    print("--- After PCA ---")
    print("Shape of pca_df:", pca_df.shape)
    print("PCA output columns:\n", pca_df.columns)

    # Concatenate the DataFrames, excluding original PCA columns from 'data'
    df = pd.concat([df, pca_df], axis=1)
    df = df.drop(columns=pca_numerical_columns, errors='ignore')  # Drop original PCA columns

    print("--- Final Data Info ---")
    print("Shape of df:", df.shape)
    print("Final data columns:\n", df.columns)
    
    return df
