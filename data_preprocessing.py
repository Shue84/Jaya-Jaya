# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeiWSJriHUBRY9ULtBpS8pOwVhgP1emy
"""

import joblib
import numpy as np
import pandas as pd

onehot_encoder = joblib.load('model/onehot_encoder.joblib')
encoder_Daytime_evening_attendance = joblib.load('model/encoder_Daytime_evening_attendance.joblib')
encoder_Fathers_occupation = joblib.load('model/encoder_Fathers_occupation.joblib')
encoder_Fathers_qualification = joblib.load('model/encoder_Fathers_qualification.joblib')
encoder_Gender = joblib.load('model/encoder_Gender.joblib')
encoder_Mothers_occupation = joblib.load('model/encoder_Mothers_occupation.joblib')
encoder_Mothers_qualification = joblib.load('model/encoder_Mothers_qualification.joblib')
encoder_Scholarship_holder = joblib.load('model/encoder_Scholarship_holder.joblib')
pca_1 = joblib.load('model/pca_1.joblib')
scaler_Age_at_enrollment = joblib.load('model/scaler_Age_at_enrollment.joblib')
scaler_Curricular_units_1st_sem_approved = joblib.load('model/scaler_Curricular_units_1st_sem_approved.joblib')
scaler_Curricular_units_1st_sem_grade = joblib.load('model/scaler_Curricular_units_1st_sem_grade.joblib')
scaler_Curricular_units_2nd_sem_approved = joblib.load('model/scaler_Curricular_units_2nd_sem_approved.joblib')
scaler_Curricular_units_2nd_sem_grade = joblib.load('model/scaler_Curricular_units_2nd_sem_grade.joblib')
scaler_Previous_qualification_grade = joblib.load('model/scaler_Previous_qualification_grade.joblib')

pca_numerical_columns = [
    'Age_at_enrollment',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Previous_qualification_grade'
]
# Define the correct order of columns for one-hot encoding
onehot_encoded_columns = ['Marital_status', 'Course', 'Previous_qualification']

def data_preprocessing(data):
    """Preprocessing data

    Args:
        data (Pandas DataFrame): Dataframe that contain all the data to make prediction

    return:
        Pandas DataFrame: Dataframe that contain all the preprocessed data
    """
    data = data.copy()
    df_processed = pd.DataFrame()

    print("--- Start of data_preprocessing ---")  # Overall entry point log
    print("Initial data shape:", data.shape)
    print("Initial NaNs:\n", data.isnull().sum())

    # Handle NaNs in numerical columns before scaling
    for col in pca_numerical_columns:
        if data[col].isnull().any():
            print(f"NaNs found in {col} before imputation.")
            data[col] = data[col].fillna(data[col].mean())
            print(f"NaNs in {col} after imputation: {data[col].isnull().sum()}")
        else:
            print(f"No NaNs in {col} before imputation.")

    # Create a dictionary to hold the scalers
    scaler_dict = {
        'Age_at_enrollment': scaler_Age_at_enrollment,
        'Curricular_units_1st_sem_approved': scaler_Curricular_units_1st_sem_approved,
        'Curricular_units_1st_sem_grade': scaler_Curricular_units_1st_sem_grade,
        'Curricular_units_2nd_sem_approved': scaler_Curricular_units_2nd_sem_approved,
        'Curricular_units_2nd_sem_grade': scaler_Curricular_units_2nd_sem_grade,
        'Previous_qualification_grade': scaler_Previous_qualification_grade,
    }

    # Scale numerical features
    for col in pca_numerical_columns:
        print(f"--- Scaling column: {col} ---")
        print("Data type before scaling:", data[col].dtype)
        print("Shape before scaling:", data[col].shape)
        print("NaNs before scaling:", data[col].isnull().sum())
        print("Example values before scaling:\n", data[col].head(10))

        # Even more robust shape handling
        if len(data[col].shape) == 1:  # 1D array (Series)
            if data[col].shape[0] == 1:  # Single value
                data[[col]] = scaler_dict[col].transform(np.array(data[col]).reshape(-1, 1))
            else:  # Multiple values in a Series
                data[[col]] = scaler_dict[col].transform(data[[col]])
        elif len(data[col].shape) == 2:  # 2D array (DataFrame)
            data[[col]] = scaler_dict[col].transform(data[[col]])
        else:
            print(f"Unexpected shape for {col}: {data[col].shape}. Skipping scaling.")
            continue  # Skip scaling if shape is unexpected

        print("Data type after scaling:", data[col].dtype)
        print("Shape after scaling:", data[col].shape)
        print("NaNs after scaling:", data[col].isnull().sum())
        print("Example values after scaling:\n", data[col].head(10))
        print("--- End scaling column: {col} ---")
        
    # One-hot encode categorical features
    encoded_cols = onehot_encoder.transform(data[onehot_encoded_columns])
    encoded_df = pd.DataFrame(encoded_cols, index=data.index, columns=onehot_encoder.get_feature_names_out())
    df_processed = pd.concat([df_processed, encoded_df], axis=1)

    # Encode other categorical features
    df_processed['Daytime_evening_attendance'] = encoder_Daytime_evening_attendance.transform(data['Daytime_evening_attendance'])
    df_processed['Fathers_occupation'] = encoder_Fathers_occupation.transform(data['Fathers_occupation'])
    df_processed['Fathers_qualification'] = encoder_Fathers_qualification.transform(data['Fathers_qualification'])
    df_processed['Gender'] = encoder_Gender.transform(data['Gender'])
    df_processed['Mothers_occupation'] = encoder_Mothers_occupation.transform(data['Mothers_occupation'])
    df_processed['Mothers_qualification'] = encoder_Mothers_qualification.transform(data['Mothers_qualification'])
    df_processed['Scholarship_holder'] = encoder_Scholarship_holder.transform(data['Scholarship_holder'])

    # Create PCA input from the scaled data
    X_pca_input = data[pca_1.feature_names_in_].copy()

    # Perform PCA
    print("--- Before PCA ---")
    print("Shape of X_pca_input:", X_pca_input.shape)
    print("NaNs in X_pca_input:\n", X_pca_input.isnull().sum())
    pca_transformed = pca_1.transform(X_pca_input)
    pca_df = pd.DataFrame(pca_transformed, index=data.index, columns=pca_numerical_columns)
    df_processed = pd.concat([df_processed, pca_df], axis=1)
    print("--- After PCA ---")
    print("Shape of df_processed:", df_processed.shape)
    print("NaNs in df_processed:\n", df_processed.isnull().sum())

    print("--- End of data_preprocessing ---")  # Overall exit point log
    return df_processed
